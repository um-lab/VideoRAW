
<!DOCTYPE HTML>
<html>
<head>
    <meta charset="utf-8" />
    <title>Reconstructing High Quality Raw Video using Temporal Affinity and Diffusion Prior</title>
	<link rel="icon" type="image/x-icon" href="../assets/css/images/favicon.ico">
    <meta content="Reconstructing High Quality Raw Video using Temporal Affinity and Diffusion Prior" name="description" />
    <meta content="summary" name="twitter:card" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link href="static/css/template.css" rel="stylesheet" type="text/css" />
    <link href="static/css/my_style.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    
    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
    <script type="text/javascript">
        WebFont.load({
            google: {
                families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic", "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic", "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic", "Changa One:400,400italic", "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic", "Varela Round:400", "Bungee Shade:regular", "Roboto:300,regular,500"]
            }
        });
    </script>
    <script type="text/javascript">
        ! function (o, c) {
            var n = c.documentElement,
                t = " w-mod-";
            n.className += t + "js", ("ontouchstart" in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
        }(window, document);
    </script>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <script type="text/javascript" src="static/js/zoom.js"></script>
    <script type="text/javascript" src="static/js/video_comparison.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MLDP9MKGC8"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-MLDP9MKGC8');
    </script>
</head>

<body>
    <div class="section hero nerf-_v2">
        <div class="container-2 nerf_header_v2 w-container">
            <h1 class="nerf_title_v2">Reconstructing High Quality Raw Video using Temporal Affinity and Diffusion Prior</h1>
            <div class="nerf_subheader_v2"></div>
            <div class="nerf_subheader_v2">
                <div>
                    <a class="nerf_authors_v2">Wencheng Han<span
                            class="text-span_nerf"></span></a>,&nbsp;&nbsp;
                    <a target="_blank" class="nerf_authors_v2">Jianbing Shen<span
                            class="text-span_nerf"></span></a>,&nbsp;&nbsp;
                    <a target="_blank" class="nerf_authors_v2">David J. Crandall<span
                            class="text-span_nerf"></span></a>,&nbsp;&nbsp;
                    <a target="_blank" class="nerf_authors_v2">Cheng-zhong Xu<span
                        class="text-span_nerf"></a>
                </div>
                <div>
                    <h1 class="nerf_affiliation_v2">University of Macau</h1>

                </div>

                <div class="external-link">
                    <a class="btn" href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Leveraging_Frame_Affinity_for_sRGB-to-RAW_Video_De-rendering_CVPR_2024_paper.pdf" role="button" target="_blank">
               
                        <i class="fa fa-file-pdf"></i> Paper </a>
                    <a class="btn" href="" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-github"></i> Code </a>
                    <a class="btn" href="https://pan.baidu.com/share/init?surl=AvVtDYRnO0hJnLPkKoM_JA" role="button" target="_blank" disabled>
                            <i class="fa fa-database"></i> Dataset (Code:dk5h) </a>
		<a class="btn" href="https://huggingface.co/spaces/wencheng256/DiffusionRAWSpace" role="button" target="_blank" disabled>
                        <i class="fa fa-desktop"></i> Demo </a>
                    
                </div>

            </div>
        </div>

    </div>


    <div data-anchor="slide1" class="section nerf_section">
        <div class="w-container grey_container">
            <h2 class="grey-heading_nerf">Abstract</h2>
            <p class="paragraph-3 nerf_text nerf_results_text">
                Due to the rich information and original data distribution, RAW data are widely used in many computer vision applications. However, the use of RAW video remains limited because of the high storage costs associated with data collection. Previous works have attempted to reconstruct RAW frames from sRGB data using small sampled metadata from the original RAW frame. Yet, these algorithms struggle with RAW video reconstruction due to the high computational cost of sampling metadata on cameras.
To address these issues, we propose a new RAW video reconstruction pipeline that de-renders high-quality RAW videos from sRGB data using only one initial RAW frame as a reference. Specifically, we introduce three new models to achieve this goal. First, we present the Temporal-Affinity Guided De-rendering Network. This network leverages the temporal affinity between adjacent frames to construct a reference RAW image from previous RAW pixels. The corresponding RAW pixels in the previous frame provide valuable information about the original RAW data distribution, aiding in the precise reconstruction of the current frame. Second, to recover the missing RAW pixels caused by camera and foreground movement, we fully exploit the rich prior information from a pre-trained diffusion model and propose the RAW In-painting Model. This model can accurately fill in hollow regions in a RAW image based on the corresponding sRGB image and the surrounding RAW context.
Lastly, we present a lightweight content-aware video clipper that automatically adjusts the clip length used for RAW video reconstruction, thereby balancing storage requirements with reconstruction quality.
To better evaluate the performance of the proposed framework across different devices, we introduce the first RAW video reconstruction benchmark that comprises RAW videos from six types of camera devices with challenging scenarios.
Experimental results demonstrate that our algorithm can accurately reconstruct RAW videos across all these scenarios.
   
                <br>
                <!-- <img  src="asset/LayoutControlNetwork.pdf"> -->
            </p>
        </div>
    </div>


	
    <!-- <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Demo Video</h2>
        <div class="grid-container-1">
            <div>
                <p class="myprompt nerf_text"> </p>
                <video class="video" playsinline autoPlay muted controls src="asset/DC-ControlNet-demo.mp4"></video>
            </div>
            <div>
    
    <div class="white_section_nerf  w-container">
                    <h2 class="grey-heading_nerf">Method</h2>
                    <div class="grid-container-1">
                        <div>
                            <p class="myprompt nerf_text"> </p>
                            <video class="video" playsinline autoPlay muted controls src="asset/DC-ControlNet_Method.mp4"></video>
                        </div>
                        <div>
				 -->
<div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Models</h2>
        <div class="grid-container-1">
            <div>
                <p class="myprompt nerf_text">Overall Pipeline            </p>
<!--                 <embed src="asset/LayoutControlNetwork.pdf" style="width:800px; margin: 0 auto;" type="application/pdf"></embed> -->
		    <img src="asset/VideoRAW-PAMI-pipeline.png" width="1000" style="display:block; margin: 0 auto;"></img>
            </div>
            <div>
        



            <div>
         

    
<div class="white_section_nerf grey_container w-container"> </div>


</html>
